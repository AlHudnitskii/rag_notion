# 2. FastAPI

Категория: Frameworks & Libraries
Статус: В процессе

## FastAPI

"FastAPI имеет богатый набор фишек: встроенная валидация через Pydantic, автоматическая документация, асинхронность из коробки, WebSockets, streaming, middleware, security, DI, exception handling, тестирование через TestClient. Это позволяет разрабатывать production-ready APIs быстро и безопасно.

### Основа и архитектура

[FastAPI](https://fastapi.tiangolo.com/) — это фреймворк для создания лаконичных и довольно быстрых HTTP API-серверов.

**FastAPI строится на:**

- **Starlette** — асинхронный веб-фреймворк (обработка запросов, routing, middleware)
- **Pydantic** — валидация данных и сериализация через Python type hints
- **Uvicorn** — ASGI сервер (асинхронный аналог WSGI)

Это позволяет получить production-ready производительность без больших затрат на оптимизацию.

## Плюсы и минусы

**Плюсы:**

- **Производительность:** Бенчмарки показывают 2-3x faster чем Flask, сопоставимо с Node.js
- **Type hints:** IDE автокомплит, ловля ошибок на этапе разработки
- **Встроенная валидация:** Pydantic автоматически проверяет тип, диапазон, формат данных
- **Auto-документация:** Swagger UI и ReDoc генерируются автоматически из кода
- **Async/await:** Нативная поддержка асинхронного кода из коробки
- **Простота:** Минималистичный API, быстро учится

**Минусы:**

- **Молодой фреймворк:** Меньше ecosystem, иногда breaking changes в обновлениях
- **ORM отдельно:** Нужно самостоятельно интегрировать SQLAlchemy, Tortoise, Piccolo
- **Async learning curve:** Новичкам сложнее разобраться с async/await
- **Меньше готовых решений:** Нет встроенного админ-панели, authentication, миграций как в Django
- **Синхронные библиотеки:** Если использовать sync функции, они будут блокировать event loop

## DI (Dependency Injection)

В программировании **«Dependency Injection»** означает, что у вашего кода есть способ объявить вещи, которые требуются для его работы и использования: «зависимости». И затем FastAPI позаботится о том, чтобы сделать всё необходимое для предоставления вашему коду этих зависимостей (сделать «инъекцию» зависимостей).

Это очень полезно, когда вам нужно:

- Обеспечить общую логику (один и тот же алгоритм снова и снова).
- Разделять соединения с базой данных.
- Обеспечить безопасность, аутентификацию, требования к ролям и т. п.

Всё это при минимизации повторения кода.

![image.png](image%20338.png)

В `Depends` передаётся только один параметр, который должен быть чем-то вроде функции. Вы **не вызываете её** напрямую (не добавляйте круглые скобки в конце), просто передаёте её как параметр в `Depends()`. 

Каждый раз, когда приходит новый запрос, **FastAPI** позаботится о:

- Вызове вашей зависимости («dependable») с корректными параметрами.
- Получении результата из вашей функции.
- Присваивании этого результата параметру в вашей *функции обработки пути*.

![image.png](image%20339.png)

Таким образом, вы пишете общий код один раз, а **FastAPI** позаботится о его вызове для ваших *операций пути*.
Это особенно полезно, когда вы используете это в **большой кодовой базе**, где вы используете **одни и те же зависимости** снова и снова во **многих *операциях пути***.
Поскольку зависимости также вызываются **FastAPI** применяются те же правила при определении ваших функций: можно использовать `async def` или обычное `def`.

## Интеграция с OpenAPI[¶](https://fastapi.tiangolo.com/ru/tutorial/dependencies/#integrated-with-openapi)

Все объявления запросов, проверки и требования ваших зависимостей (и подзависимостей) будут интегрированы в ту же схему OpenAPI.

Поэтому в интерактивной документации будет вся информация и из этих зависимостей:

![image.png](image%20340.png)

Простота системы **Dependency Injection** делает **FastAPI** совместимым с:

- всеми реляционными базами данных
- NoSQL базами данных
- внешними пакетами
- внешними API
- системами аутентификации и авторизации
- системами мониторинга использования API
- системами инъекции данных в ответы

## **BackgroundTasks**

FastAPI позволяет создавать фоновые задачи, которые будут выполняться после возврата ответа. Это полезно для операций, которые должны произойти после HTTP-запроса, но клиенту не обязательно ждать их завершения, чтобы получить ответ.

Пример таких задач:

- уведомления по электронной почте
- обработка данных

### **Использование `BackgroundTasks`**

Сначала импортируйте `BackgroundTasks` и объявите параметр в вашей функции‑обработчике пути с типом `BackgroundTasks`:

![image.png](image%20341.png)

`.add_task()` принимает следующие аргументы:

- Функцию задачи, которую нужно выполнить в фоне (`write_notification`).
- Последовательность позиционных аргументов, которые должны быть переданы функции задачи, в порядке (`email`).
- Любые именованные аргументы, которые должны быть переданы функции задачи (`message="some notification"`).

Использование `BackgroundTasks` также работает с DI, т.е. можно объявить параметр типа `BackgroundTasks` на нескольких уровнях: в функции‑обработчике пути, в зависимости (dependable), в подзависимости и т. д.

**FastAPI** знает, что делать в каждом случае и как переиспользовать один и тот же объект, так чтобы все фоновые задачи были объединены и затем выполнены в фоне:

![image.png](image%20342.png)

Класс `BackgroundTasks` приходит напрямую из [`starlette.background`](https://www.starlette.dev/background/).

Он импортируется/включается прямо в FastAPI, чтобы вы могли импортировать его из `fastapi` и избежать случайного импорта альтернативного `BackgroundTask` (без `s` на конце) из `starlette.background`.

Если вам нужно выполнять тяжелые вычисления в фоне, и при этом они не обязательно должны запускаться тем же процессом (например, вам не нужно делиться памятью, переменными и т. п.), вам могут подойти более мощные инструменты, такие как [Celery](https://docs.celeryq.dev/).

Они обычно требуют более сложной конфигурации, менеджера очереди сообщений/заданий (например, RabbitMQ или Redis), но позволяют запускать фоновые задачи в нескольких процессах и, что особенно важно, на нескольких серверах.

Но если вам нужен доступ к переменным и объектам из того же приложения **FastAPI**, или нужно выполнять небольшие фоновые задачи (например, отправку email‑уведомления), вы можете просто использовать `BackgroundTasks`.

### Celery and `BackgroundTasks`

Используйте Celery для сложных, распределенных задач, которые требуют надежности, масштабируемости и управления очередями, а `BackgroundTasks` — для простых, одноразовых задач, выполняющихся в рамках одного процесса. 

|  | Celery | **BackgroundTasks** |
| --- | --- | --- |
| Использование | Сложные задачи с возможностью масштабирования | Простые, одноразовые задачи, выполняющиеся внутри одного и того же веб-сервера |
| Принцип работы | Задачи помещаются в очередь, а рабочие процессы извлекают их из очереди и выполняют | Задачи выполняются в отдельном потоке в рамках того же самого процесса |
| Преимущества | Высокая надежность, масштабируемость и создания периодических задач | Простота реализации и минимальные накладные расходы |
| Ограничения | -  | Не подходит для высоконагруженных задач, требующих масштабирования, так как не может использовать отдельные рабочие узлы |

## **WSGI, ASGI и RSGI**

Веб-сервер - программа. которая запускает Python-приложение и обеспечивает его взаимодействие с внешним миром по протоколу HTTP (или если нужно WS).

Веб-сервер принимает внешние запросы, передаёт их в приложение через интерфейс (WSGI, ASGI или RSGI), а затем возвращает ответ. Проще говоря, веб-сервер — это связующее звено между кодом и пользователем.

Для "общения" между веб-сервером и приложением существует три интерфейса взаимодействия:

- **WSGI** (Web Server Gateway Interface).
- **ASGI** (Asynchronous Server Gateway Interface).
- **RSGI** (Rust Server Gateway Interface).

### **WSGI (Web Server Gateway Interface)**

Стандарт интерфейса между Python-приложением и веб-сервером:

- **Синхронный** интерфейс взаимодействия — обрабатывает запросы один за другим.
- Применяется преимущественно в "классических" фреймворках, вроде Django или Flask.
- Не поддерживает WebSocket, SSE (Server-Sent Events) и некоторые другие возможности.

Достаточно простой интерфейс, подходящий для небольших и низконагруженных приложений.

### **ASGI (Asynchronous Server Gateway Interface)**

Современный стандарт интерфейса для Python-приложений. Придуман как "духовный наследник" WSGI.

- **Синхронный и асинхронный** интерфейс взаимодействия — может обрабатывать множество запросов одновременно.
- Применяется в "молодых" фреймворках, вроде FastAPI, а также может применяться в Django (через Channels) или Flask.
- Поддерживает WebSocket, SSE, HTTP/2 и так далее.

Актуальный интерфейс взаимодействия для больших и высоконагруженных приложений.

### **RSGI (Rust Server Gateway Interface)**

Новый проект (2024-2025), вдохновлённый WSGI/ASGI, но созданный с прицелом на **Rust + Python** экосистему. Его продвигают разработчики Granian и Uvicorn.

- Идея: минималистичный интерфейс между веб-сервером и приложением.
- Оптимизирован для Rust-бэкендов и Python-приложений, чтобы убрать избыточные прослойки.
- Цель — заменить ASGI/WSGI в будущих фреймворках.
- Поддерживает синхронные, асинхронные и нативные Rust-хендлеры.
- Акцент на высокую производительность и простоту (ASGI со временем оброс сложностями).

Экспериментальный интерфейс, появившийся совсем недавно. Может проявить себя в высоконагруженных приложениях, написанных на Python, или комбинированных системах, использующих не только Python, но и Rust.

## **Python веб-серверы**

### **Gunicorn (WSGI)**

Лёгкий WSGI-сервер для Python. Широко используется с Django/Flask. Работает по схеме prefork (несколько процессов-воркеров).

- **Конфигурация:** простая. Например, `gunicorn --workers 4 myproject.wsgi:application`. Хорошо масштабируется на нескольких ядрах. **Формула расчета воркеров**: рекомендуется число воркеров ≈ (2 × количество CPU ядер) + 1.
- **Особенности:** реализует только WSGI, **не поддерживает ASGI/async** "из коробки". Для работы с асинхронными задачами можно применять сторонние классы воркеров (gevent/eventlet) или и спользовать `gunicorn` + `uvicorn`воркеры. Не имеет встроенной поддержки WebSocket (только HTTP).
- **Производительность:** хорошие показатели для синхронных нагрузок. **~3 000-10 000 запросов/сек** — в зависимости от числа воркеров, окружения, нагрузки. При этом память на воркер ~30 MB.

### **uWSGI (WSGI)**

"Полноценный" веб-сервер/приложение-сервер. Поддерживает WSGI, FastCGI, HTTP и др. Можно использовать в режиме префорк или с потоками/Greenlets.

- **Конфигурация:** очень гибкая и сложная. Требует конфигурационного файла (uwsgi.ini) с множеством опций (процессы, потоки, кеширование, балансировка). Из-за богатого набора опций порог вхождения высок.
- **Особенности:** предназначен для высоких нагрузок и масштабируемых систем (например, Emperor mode, multiple apps). Поддерживает горячую замену кода, кэширование и балансировку процессов.
- **Производительность:** несколько лучше, чем у Gunicorn в бенчмарках: **10-12 тысяч запросов/сек**. Память на воркер чуть выше — 40 MB.

### **Uvicorn (ASGI)**

Лёгкий ASGI-сервер для Python. Построен на основе uvloop и httptools (Cython). Предназначен для асинхронных приложений (Starlette, FastAPI, Django Channels).

- **Конфигурация:** очень простая. Запускается одной командой: `uvicorn myapp.asgi:application --workers 4`. Не имеет сложных конфигов, можно задавать параметры в CLI или скрипте Python.
- **Особенности:** поддерживает HTTP/1.1, HTTP/2, WebSocket. Имеет низкий оверхед и малый размер кода, использует готовые асинхронные event loop (uvloop).
- **Производительность:** высокая: **~35 000-40 000 запросов/сек**. Низкая задержка. Память на воркер примерно 20 MB.

### **Granian (WSGI, ASGI, RSGI, Rust)**

Новый HTTP-сервер для Python-приложений, написанный на Rust (использует Hyper/Tokio). Поддерживает сразу WSGI, ASGI и RSGI-интерфейсы.

- **Конфигурация:** простой CLI или кодовый API. Например, `granian --interface asgi myapp:app` для запуска ASGI-приложения. Можно задавать количество процессов/потоков.
- **Особенности:** ориентирован на максимальную производительность и пропускную способность. Из коробки поддерживает HTTP/1, HTTP/2, WebSocket'ы, HTTPS, статические файлы. Можно конфигурировать SSL/mTLS, расширения ASGI. Лёгкий (нет проблем с GIL, может использовать Rust-потоки).
- **Производительность:** очень высокая: **~40 000-45 000 запросов/сек** в ASGI-режиме и **~40 000 запросов/сек** в WSGI-режиме. Максимальная пропускная способность. Память на процесс ~15 MB.

**RSGI не поддерживается существующими фреймворками вроде Django или Flask**, поэтому применять его можно только с библиотеками/фреймворками, изначально рассчитанными на асинхронный стек. Для FastAPI RSGI может дать буст, но для Django он неприменим (на момент написания статьи).

### **Основные выводы:**

1. **ASGI-серверы** значительно превосходят WSGI по производительности
2. **Granian** показывает лучшие результаты как по скорости, так и по потреблению памяти
3. **Выбор сервера** зависит от требований проекта: для простых приложений достаточно Gunicorn, для высоконагруженных — Uvicorn или Granian
4. **Rust-решения** в Python-экосистеме становятся трендом, обеспечивая лучшую производительность